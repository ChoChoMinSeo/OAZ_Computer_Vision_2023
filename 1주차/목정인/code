import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from tqdm import tqdm
device = 'cuda' if torch.cuda.is_available() else 'cpu'

# Timer Decorator: 함수 실행하는 데 걸리는 시간 측정
import time
def timer(func):
    def wrapper(*args, **kwargs):
        start_time = time.time()
        result = func(*args, **kwargs)
        end_time = time.time()
        computation_time = end_time - start_time
        print(f"Execution time of {func.__name__}: {computation_time} seconds")
        return result
    return wrapper

# Hyperparameters
CONFIG = {
    'lr': 0.1,
    'epochs': 100,
    'min_batch': 32,
    'dropout': 0.0,
    'weight_decay': 0,
}

import os
import zipfile
from itertools import chain, repeat

# Prepare data
def prepare_dogs_cats(dirname='/content/cats_and_dogs_filtered', download=False):
    if download:
        !wget --no-check-certificate \
        https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \
        -O /tmp/cats_and_dogs_filtered.zip
        local_zip = '/tmp/cats_and_dogs_filtered.zip'
        zip_ref = zipfile.ZipFile(local_zip, 'r')
        zip_ref.extractall('/content')
        zip_ref.close()
    base_dir = dirname
    train_dir = os.path.join(base_dir, 'train')
    validation_dir = os.path.join(base_dir, 'validation')
    # Directory with our training cat pictures
    train_cats_dir = os.path.join(train_dir, 'cats')
    train_dogs_dir = os.path.join(train_dir, 'dogs')
    val_cats_dir = os.path.join(validation_dir, 'cats')
    val_dogs_dir = os.path.join(validation_dir, 'dogs')
    train_cat_fnames = os.listdir(train_cats_dir)
    train_dog_fnames = os.listdir(train_dogs_dir)
    val_cat_fnames = os.listdir(val_cats_dir)
    val_dog_fnames = os.listdir(val_dogs_dir)
    number_of_train_cat = len(os.listdir(train_cats_dir))
    number_of_train_dog = len(os.listdir(train_dogs_dir))
    number_of_val_cat = len(os.listdir(val_cats_dir))
    number_of_val_dog = len(os.listdir(val_dogs_dir))
    train_fnames_list = [os.path.join(train_cats_dir, fname) for fname in train_cat_fnames] + [os.path.join(train_dogs_dir, fname) for fname in train_dog_fnames]
    val_fnames_list = [os.path.join(val_cats_dir, fname) for fname in val_cat_fnames] + [os.path.join(val_dogs_dir, fname) for fname in val_dog_fnames]
    #Labeling 0: cat, 1: dog
    train_label_list = list(chain.from_iterable((repeat(label, num) for (label, num) in zip([0, 1], [number_of_train_cat, number_of_train_dog]))))
    val_label_list = list(chain.from_iterable((repeat(label, num) for (label, num) in zip([0, 1], [number_of_val_cat, number_of_val_dog]))))

    return train_fnames_list, train_label_list, val_fnames_list, val_label_list

# Dataset
import torchvision as tv
from torchvision import transforms
from torch.utils.data import Dataset
from torch.utils.data.dataloader import DataLoader
import PIL.Image as Image

# Data Augmentation with Rotation, Affine transform, Jittering
train_transform = transforms.Compose(
                    [
                    transforms.ColorJitter(brightness=0.05, contrast=0.05, saturation=0.05, hue=0.05), #밝기, 대비, 채도, 색상 조정
                    transforms.RandomRotation(20),
                    transforms.RandomAffine(degrees=20, translate=(0.1,0.1), scale=(0.9, 1.1)),
                    transforms.Resize((128, 128)),
                    transforms.ToTensor(),
                    ])


class dataset_dogs_cats(Dataset):
    def __init__(self, file_path='/content/cats_and_dogs_filtered',
                 train=True,
                 download=False,
                 transform=None):

        train_fnames_list, train_label_list, val_fnames_list, val_label_list = prepare_dogs_cats(dirname=file_path, download=download)

        if train:
            self.img_path = train_fnames_list
            self.target = train_label_list
        else:
            self.img_path = val_fnames_list
            self.target = val_label_list

        if transform is None:
            self.transform = tv.transforms.Compose([transforms.Resize((128, 128)),
                                                    transforms.ToTensor()])
        else:
            self.transform = transform

    def __len__(self):
        return len(self.target)

    def __getitem__(self, index):

       img = self.transform(Image.open(self.img_path[index]))
       label = self.target[index]

       return img, label

train_dataset = dataset_dogs_cats(train=True, transform=train_transform, download=True)
test_dataset = dataset_dogs_cats(train=False, transform=None)

train_loader = DataLoader(dataset=train_dataset, batch_size=CONFIG['min_batch'], shuffle=True)
test_loader = DataLoader(dataset=test_dataset, batch_size=CONFIG['min_batch'], shuffle=False)

import matplotlib.pyplot as plt

x, y = next(iter(train_loader))
print(x.shape, y.shape)
classes = ['cat', 'dog']

def my_imgshow(img, label):
    fig, ax1 = plt.subplots(1,1)
    if img.shape[0] == 3:
        img = np.transpose(img, (1, 2, 0)) # change order into (H, W, C)
    img = ax1.imshow(img)
    ax1.set_title('label: {}'.format(classes[label]))
    plt.show()

my_imgshow(x[0], y[0])

# Training code
def make_train_step(model, loss_fn, optimizer):
    def train_step_fn(x, y):

        model.train()
        y_hat = model(x)
        loss = loss_fn(y_hat, y)
        loss.backward()
        optimizer.step()
        optimizer.zero_grad()

        return loss.item()
    return train_step_fn

def evaluate_step(x, y):
    y_hat = model(x)
    result = torch.sum(torch.argmax(y_hat, axis=1) == y)
    return result, len(y)

@timer
def train_model(epochs=1000, eval_test_accuracy=False):

    for epoch in tqdm(range(epochs), desc='train'):
        model.train()
        mini_batch_losses = []
        for x_minibatch, y_minibatch in train_loader:
            x_minibatch = x_minibatch.to(device)
            y_minibatch = y_minibatch.to(device)
            mini_batch_loss = train_step(x_minibatch, y_minibatch)
            mini_batch_losses.append(mini_batch_loss)

        # Evaluate train loss
        if (epoch + 1) % 10 == 0:
            loss = np.mean(mini_batch_losses)
            print("train loss at {} epoch:{}".format(epoch + 1, loss))

        # Evaluate test accuracy
    if eval_test_accuracy:
        model.eval()
        with torch.no_grad():
            test_accuracy = 0
            test_result = 0
            test_cnt = 0
            for x_minibatch_test, y_minibatch_test in test_loader:
                x_minibatch_test = x_minibatch_test.to(device)
                y_minibatch_test = y_minibatch_test.to(device)
                result, cnt = evaluate_step(x_minibatch_test, y_minibatch_test)
                test_result += result
                test_cnt += cnt
            test_accuracy = 100 * test_result / test_cnt
            print("test accuracy: {}%".format(test_accuracy))

#resnet18 모델 
import torchvision.models as models

class ResNet(nn.Module):
    def __init__(self):
        super().__init__()
        # Initial Setting
        self.resnet = models.resnet18()
        self.resnet.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=3, bias=False)
        self.classifier = nn.Linear(1000, 2, dtype=torch.float32)

    def forward(self, x):
    # Computes the outputs / predictions
        z = self.resnet(x)
        z = z.view(z.size(0), -1)
        y_hat = self.classifier(z)
        return y_hat

model = ResNet().to(device)
loss_fn = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=CONFIG['lr'], weight_decay=CONFIG['weight_decay'])
train_step = make_train_step(model, loss_fn, optimizer)

# Train Convolutional Nets
train_model(CONFIG['epochs'], eval_test_accuracy=True)
